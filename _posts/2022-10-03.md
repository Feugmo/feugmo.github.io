---
layout: post
title: Graph Neural Networks as gradient flows
date: 2022-10-03 10:44:00
description: Medium
---


Under a few simple constraints, Graph Neural Networks can be derived as gradient flows minimising a learnable energy that describes attractive and repulsive forces in the feature space. This formalism allows the interpretation of GNNs as physical systems and sheds light onto how the interaction between the graph frequencies and the channel-mixing spectrum determine the evolution of the node features and control whether the dynamics is “smoothing” or “sharpening.” It also leads to a surprising conclusion: even very simple graph convolutional models with shared weights do not necessarily suffer from over-smoothing and can be efficient in heterophilic settings.
